@inproceedings{manzoni2024personalized,
  title={Personalized Facial Gesture Recognition for Accessible Mobile Gaming},
  author={Manzoni, Matteo and Ahmetovic, Dragan and Mascetti, Sergio},
  booktitle={International Conference on Computers Helping People with Special Needs},
  pages={120--127},
  year={2024},
  organization={Springer},
    abstract={For people with upper extremity motor impairments, interaction with mobile devices is challenging because it relies on the use of the touchscreen. Existing assistive solutions replace inaccessible touchscreen interactions with sequences of simpler and accessible ones. However, the resulting sequence takes longer to perform than the original interaction, and therefore it is unsuitable for mobile video games. In this paper, we expand our prior work on accessible interaction substitutions for video games with a new interaction modality: using facial gestures. Our approach allows users to play existing mobile video games using custom facial gestures. The gestures are defined by each user according to their own needs, and the system is trained with a small number of face gesture samples collected from the user. The recorded gestures are then mapped to the touchscreen interactions required to play a target game. Each interaction corresponds to a single face gesture, making this approach suitable for the interaction with video games. We describe the facial gesture recognition pipeline, motivating the implementation choices through preliminary experiments conducted on example videos of face gestures collected by one user without impairments. Preliminary results show that an accurate classification of facial gestures (97%) is possible even with as few as 5 samples of the user.},
    pdf={manzoni2024personalized.pdf},
    doi={https://doi.org/10.1007/978-3-031-62846-7_15},
    bibtex_show={true},
    selected={true}
}

@inproceedings{ahmetovic2024insights,
  title={Insights on the Development of PRACTICE, A Research-Oriented Healthcare Platform},
  author={Ahmetovic, Dragan and Angileri, Alessio and Arcudi, Sara and Bettini, Claudio and Civitarese, Gabriele and Colussi, Marco and Giachi, Andrea and Gualtierotti, Roberta and Mascetti, Sergio and Manzoni, Matteo and others},
  booktitle={2024 IEEE International Conference on Smart Computing (SMARTCOMP)},
  pages={380--385},
  year={2024},
  organization={IEEE Computer Society},
    abstract={This paper describes the development of PRACTICE, a distributed healthcare technological platform that supports various research initiatives by the University of Milan and the Angelo Bianchi Bonomi Hemophilia and Thrombosis Center, Fondazione IRCCS Ca’ Granda, Ospedale Maggiore Policlinico. PRACTICE includes three main components: a mobile app that patients can use to self-acquire ultrasound images at home, a computer-aided diagnosis web application that supports the practitioners through a set of machine learning models, and a set of web tools for image annotation, a prerequisite for training the machine learning models. Although PRACTICE was designed in the specific context of supporting the detection of joint recess blood effusions in hemophilic patients, this paper describes the main design and implementation challenges that apply to other applications of a research-oriented health platform.},
    pdf={ahmetovic2024insights.pdf},
    doi={https://doi.org/10.1109/SMARTCOMP61445.2024.00085},
    bibtex_show={true}
}

@article{manzoni2025mapio,
  title={MapIO: a Gestural and Conversational Interface for Tactile Maps},
  author={Manzoni, Matteo and Mascetti, Sergio and Ahmetovic, Dragan and Crabb, Ryan and Coughlan, James M},
  journal={IEEE Access},
  year={2025},
  publisher={IEEE},
    abstract={This paper describes the development of PRACTICE, a distributed healthcare technological platform that supports various research initiatives by the University of Milan and the Angelo Bianchi Bonomi Hemophilia and Thrombosis Center, Fondazione IRCCS Ca’ Granda, Ospedale Maggiore Policlinico. PRACTICE includes three main components: a mobile app that patients can use to self-acquire ultrasound images at home, a computer-aided diagnosis web application that supports the practitioners through a set of machine learning models, and a set of web tools for image annotation, a prerequisite for training the machine learning models. Although PRACTICE was designed in the specific context of supporting the detection of joint recess blood effusions in hemophilic patients, this paper describes the main design and implementation challenges that apply to other applications of a research-oriented health platform.},
    pdf={manzoni2025mapio.pdf},
    doi={https://doi.org/10.1109/ACCESS.2025.3566286},
    bibtex_show={true},
    selected={true}
}

@article{ahmetovic2025shared,
  title={Shared Control for Game Accessibility: Understanding Current Human Cooperation Practices to Inform the Design of Partial Automation Solutions},
  author={Ahmetovic, Dragan and Manzoni, Matteo and Corti, Filippo and Mascetti, Sergio},
  journal={arXiv preprint arXiv:2509.02132},
  year={2025},
    abstract={Shared control is a form of video gaming accessibility support that allows players with disabilities to delegate inaccessible controls to another person. Through interviews involving 14 individuals with lived experience of accessible gaming in shared control, we explore the ways in which shared control technologies are adopted in practice, the accessibility challenges they address, and how the support currently provided in shared control can be automated to remove the need for a human assistant. Findings indicate that shared control is essential for enabling access to otherwise inaccessible games, but its reliance on human support is a key limitation. Participants welcomed the idea of automating the support with software agents, while also identifying limitations and design requirements. Accordingly, this work contributes insights into current practices and proposes guidelines for developing automated support systems.},
    pdf={ahmetovic2025shared.pdf},
    doi={https://doi.org/10.48550/arXiv.2509.02132},
    bibtex_show={true},
    selected={true}
}

@inproceedings{ahmetovic2025camio,
  title={CamIO in the Browser: A Cross-Platform Audio Label Tool for Tactile Graphics},
  author={Ahmetovic, Dragan and Coughlan, James and Dal Santo, Giorgio and Ezrouri, Khadija and Manzoni, Matteo and Mascetti, Sergio},
  booktitle={Adjunct Proceedings of the 27th International Conference on Mobile Human-Computer Interaction},
  pages={1--3},
  year={2025},
    abstract={For blind or low vision individuals, tactile graphics (TGs) provide essential spatial information but are restricted in the amount of data they can convey – especially semantic information, which is represented using the small amount of braille abbreviations that fit on the TG. Using computer vision, TGs can be enhanced by adding audio labels, in which audio descriptions are triggered when the user touches elements on the TG; these audio descriptions can contain unlimited amounts of semantic information and are accessible even to those who don’t read braille. Unfortunately, existing audio label systems are closed systems with severe limitations, some of which are costly and/or tied to specific hardware platforms. We address this problem by creating CamIO-Web, an open-source version of our CamIO (short for “Camera Input-Output”) audio label system, which runs in the browser of virtually any computer or mobile device. The system includes facilities that allow users to create their own TGs with any audio labels (audio recordings or Text-to-Speech), and the open-source code base makes it extensible.},
    doi={https://doi.org/10.1145/3737821.3748528},
    bibtex_show={true}
}

@inproceedings{ahmetovic2025interactive,
  title={Interactive Guidance for Self-Acquisition of Ultrasound Images by Hemophilic Patients},
  author={Ahmetovic, Dragan and Bettini, Claudio and Colussi, Marco and Giacoia, Stefano and Gualtierotti, Roberta and Manzoni, Matteo and Mascetti, Sergio and Peyvandi, Flora},
  booktitle={Adjunct Proceedings of the 27th International Conference on Mobile Human-Computer Interaction},
  pages={1--5},
  year={2025},
    abstract={Timely diagnosis of joint bleeds is crucial for preventing long-term damage in patients with hemophilia. However, access to specialized care and the operator-dependent nature of ultrasound imaging pose significant challenges for remote monitoring. We present GAJA (Guided self-Acquisition of Joint ultrAsound images), a mobile system that interactively guides patients during the acquisition of joint ultrasound images without requiring real-time supervision. The version of GAJA presented in this paper extends support beyond the knee to include elbow and ankle joints and integrates with the CADET platform, enabling clinicians to remotely assess the acquired images. In this demo, we showcase GAJA’s real-time guidance interaction and its integration with remote clinical workflows.},
    doi={https://doi.org/10.1145/3737821.3748527},
    bibtex_show={true}
}
